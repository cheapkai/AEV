{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJ90N4m1COCheZG6ExoKLi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cheapkai/AEV/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO_Mu2i3YgYA"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BjwWAQpnMKa",
        "outputId": "e627ba11-dedb-456a-9d96-3fec175cdb5e"
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tFTnmFvpYgc"
      },
      "source": [
        "input = torch.randn(20, 100, 35, 45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iX1CWDyp63v",
        "outputId": "8816a5bf-9592-4086-db50-0336292d8fb5"
      },
      "source": [
        "print(input.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 100, 35, 45])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyUibHufM0l7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqPRY5U_N3eX"
      },
      "source": [
        "#########\n",
        "#--  Copyright (c) 2016, Facebook, Inc.\n",
        "#--  All rights reserved.\n",
        "#--\n",
        "#--  This source code is licensed under the BSD-style license found in the\n",
        "#--  LICENSE file in the root directory of this source tree. An additional grant\n",
        "#--  of patent rights can be found in the PATENTS file in the same directory.\n",
        "#--\n",
        "\n",
        "#------------\n",
        "#-- This file automatically downloads the CIFAR-100 dataset from\n",
        "#--    http://www.cs.toronto.edu/~kriz/cifar-100-binary.tar.gz\n",
        "#-- It is based on cifar10-gen.lua\n",
        "#-- Ludovic Trottier\n",
        "#------------\n",
        "################\n",
        "\n",
        "\n",
        "\n",
        "local URL = 'http://www.cs.toronto.edu/~kriz/cifar-100-binary.tar.gz'\n",
        "\n",
        "local M = {}\n",
        "\n",
        "local function convertCifar100BinToTorchTensor(inputFname)\n",
        "   local m=torch.DiskFile(inputFname, 'r'):binary()\n",
        "   m:seekEnd()\n",
        "   local length = m:position() - 1\n",
        "   local nSamples = length / 3074 -- 1 coarse-label byte, 1 fine-label byte, 3072 pixel bytes\n",
        "\n",
        "   assert(nSamples == math.floor(nSamples), 'expecting numSamples to be an exact integer')\n",
        "   m:seek(1)\n",
        "\n",
        "   local coarse = torch.ByteTensor(nSamples)\n",
        "   local fine = torch.ByteTensor(nSamples)\n",
        "   local data = torch.ByteTensor(nSamples, 3, 32, 32)\n",
        "   for i=1,nSamples do\n",
        "      coarse[i] = m:readByte()\n",
        "      fine[i]   = m:readByte()\n",
        "      local store = m:readByte(3072)\n",
        "      data[i]:copy(torch.ByteTensor(store))\n",
        "   end\n",
        "\n",
        "   local out = {}\n",
        "   out.data = data\n",
        "   -- This is *very* important. The downloaded files have labels 0-9, which do\n",
        "   -- not work with CrossEntropyCriterion\n",
        "   out.labels = fine + 1\n",
        "   out.coarse = coarse + 1\n",
        "   return out\n",
        "end\n",
        "\n",
        "function M.exec(opt, cacheFile)\n",
        "   print(\"=> Downloading CIFAR-100 dataset from \" .. URL)\n",
        "   \n",
        "   local ok = os.execute('curl ' .. URL .. ' | tar xz -C  gen/')\n",
        "   assert(ok == true or ok == 0, 'error downloading CIFAR-100')\n",
        "\n",
        "   print(\" | combining dataset into a single file\")\n",
        "   \n",
        "   local trainData = convertCifar100BinToTorchTensor('gen/cifar-100-binary/train.bin')\n",
        "   local testData = convertCifar100BinToTorchTensor('gen/cifar-100-binary/test.bin')\n",
        "\n",
        "   print(\" | saving CIFAR-100 dataset to \" .. cacheFile)\n",
        "   torch.save(cacheFile, {\n",
        "      train = trainData,\n",
        "      val = testData,\n",
        "   })\n",
        "end\n",
        "\n",
        "W = M\n",
        "\n",
        "return M"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfX4rrRwOtd6"
      },
      "source": [
        "print(W.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcEXppGqLQNU"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.hb = torch.zeros(1, 28, 28)\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "    self.bn1 = nn.BatchNorm2d(100)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv2 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "    self.bn2 = nn.BatchNorm2d(100)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = x + self.hb\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.bn2(x)\n",
        "\n",
        "    self.hb = x\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "class Model2(nn.Module, Model):\n",
        "\n",
        "  def __init__(self, depth):\n",
        "\n",
        "    super(Model2, self).__init__(depth)    \n",
        "\n",
        "    self.phydep = depth\n",
        "    self.layers = []\n",
        "\n",
        "    for i in range(self.phydep):\n",
        "      self.layers.append(Model())\n",
        "    \n",
        "    self.pool = nn.MaxPool2d(28, strides=2)\n",
        "    self.fc = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    self.forp = x\n",
        "    for i in range(self.phydep):\n",
        "      self.forp = self.layers[i].forward(self.forp)\n",
        "    \n",
        "    self.forp = self.pool(self.forp)\n",
        "    self.forp = self.fc(self.forp)\n",
        "\n",
        "    return self.forp\n",
        "\n",
        "class Model3():\n",
        "  def __init__(self):\n",
        "    self.mod = nn.CrossEntropyLoss()\n",
        "\n",
        "  def fun(self, t, itrn, input, targetf, targetc):\n",
        "    l = self.mod(input, targetc)\n",
        "    k = self.mod(input, targetf)\n",
        "    ee = t/itrn\n",
        "    m = l*ee + (1-ee)*k\n",
        "\n",
        "    return m\n",
        "    \n",
        "\n",
        "class fbnetz9(Model, Model2, Model3):\n",
        "\n",
        "  def __init__(self, depth):\n",
        "\n",
        "    self.stack2 = Model2(depth)\n",
        "\n",
        "  #train \n",
        "  def get_accuracy(self, logit, target, batchsize):\n",
        "    \" Obtain accuracy for training round\"\n",
        "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects/batchsize\n",
        "    return accuracy.item()\n",
        "\n",
        "  def train(self, trainloader, lr, itrn):\n",
        "\n",
        "    for images, labels in trainloader:\n",
        "      print(\"batch size\", images.shape)\n",
        "      out = self.stack2(images)\n",
        "      print(out.shape)\n",
        "      break\n",
        "    \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.stack2 = self.stack2.to(device)\n",
        "    criterion = Model3()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    temporalskip = []\n",
        "    n=2\n",
        "    for itr in range(itrn):\n",
        "      train_running_loss = 0.0\n",
        "      train_acc = 0.0\n",
        "      #model = model.train()\n",
        "      \n",
        "      for i, (images, labels) in enumerate(trainloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        if itr >= n:\n",
        "          images = images + temporalskip[itr-n]\n",
        "        logits = model(images)\n",
        "        #what is a hidden state\n",
        "        temporalskip.append(logits)\n",
        "        loss = criterion(logits, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_running_loss += loss.detach.item()\n",
        "        train_acc += self.get_accuracy(logits, labels, batchsize)\n",
        "        \n",
        "\n",
        "  \n",
        "\n",
        "def test(testloader):\n",
        "\n",
        "  images = images.to(device)\n",
        "  labels = labels.to(device)\n",
        "  outputs = Stack2.forward()\n",
        "  test_acc+=get_accuracy(outputs, labels, batchsize)\n",
        "\n",
        "  \n",
        "       \n",
        "\n",
        "\n",
        "     \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}